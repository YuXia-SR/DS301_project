{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "US_zipcode = pd.read_csv('/Users/Bennyw/Desktop/DS301 project/Twitter_Data/uszips.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/JustAnotherArchivist/snscrape.git\n",
      "  Cloning https://github.com/JustAnotherArchivist/snscrape.git to /private/var/folders/nr/dl33j47d33z0cnhd9q6f1jcm0000gp/T/pip-req-build-br0g8oyk\n",
      "Requirement already satisfied: requests[socks] in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (2.24.0)\n",
      "Requirement already satisfied: lxml in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (4.6.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (4.9.3)\n",
      "Requirement already satisfied: filelock in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (3.0.12)\n",
      "Requirement already satisfied: pytz in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from snscrape==0.4.3.20220107.dev45+ged3ea94) (2020.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev45+ged3ea94) (3.0.4)\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev45+ged3ea94) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev45+ged3ea94) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape==0.4.3.20220107.dev45+ged3ea94) (1.7.1)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->snscrape==0.4.3.20220107.dev45+ged3ea94) (2.0.1)\n",
      "Building wheels for collected packages: snscrape\n",
      "  Building wheel for snscrape (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for snscrape: filename=snscrape-0.4.3.20220107.dev45+ged3ea94-py3-none-any.whl size=67036 sha256=75914eb6d315e19247d25c62fcea84ed89a1404b4e6436ae4a71a8446b6da50f\n",
      "  Stored in directory: /private/var/folders/nr/dl33j47d33z0cnhd9q6f1jcm0000gp/T/pip-ephem-wheel-cache-bjgmcmvo/wheels/92/42/87/33fa9b18f7a75d02643a9ca3743339aec9be28c6796267c7d8\n",
      "Successfully built snscrape\n",
      "Installing collected packages: snscrape, urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.9\n",
      "    Uninstalling urllib3-1.26.9:\n",
      "      Successfully uninstalled urllib3-1.26.9\n",
      "\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "conda 4.11.0 requires ruamel_yaml_conda>=0.11.14, which is not installed.\n",
      "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
      "selenium 4.1.0 requires urllib3[secure]~=1.26, but you'll have urllib3 1.25.11 which is incompatible.\n",
      "elastic-transport 8.1.2 requires urllib3<2,>=1.26.2, but you'll have urllib3 1.25.11 which is incompatible.\u001b[0m\n",
      "Successfully installed snscrape-0.4.3.20220107.dev45+ged3ea94 urllib3-1.25.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/JustAnotherArchivist/snscrape.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our search term, using syntax for Twitter's Advanced Search\n",
    "search = 'Moderna stock'\n",
    "\n",
    "# the scraped tweets, this is a generator\n",
    "scraped_tweets = sntwitter.TwitterSearchScraper(search).get_items()\n",
    "\n",
    "# slicing the generator to keep only the first 100 tweets\n",
    "sliced_scraped_tweets = itertools.islice(scraped_tweets, 10000)\n",
    "\n",
    "# convert to a DataFrame and keep only relevant columns\n",
    "df = pd.DataFrame(sliced_scraped_tweets)[['date', 'content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-29 16:30:18+00:00</td>\n",
       "      <td>@TulsiGabbard I never agree with you,but this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-29 16:28:17+00:00</td>\n",
       "      <td>@MauricioContrer Hola vecino! Depende del stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-29 15:42:46+00:00</td>\n",
       "      <td>Moderna Stock: Everything You Need To Know | v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-29 15:32:51+00:00</td>\n",
       "      <td>Moderna Files to Expand Conditional Marketing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-29 15:32:21+00:00</td>\n",
       "      <td>Moderna Files to Expand Conditional Marketing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2021-12-03 21:04:21+00:00</td>\n",
       "      <td>@ogaten10 @AkhigbeSam_ Moderna, plitzer and ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2021-12-03 20:55:02+00:00</td>\n",
       "      <td>@miikee_t Been saying to buy moderna stock sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2021-12-03 20:39:51+00:00</td>\n",
       "      <td>Donc vs avez eu vos 2 doses de #Pfizer mais co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2021-12-03 20:38:08+00:00</td>\n",
       "      <td>Pfizer and Moderna are projected to make $93 B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2021-12-03 20:17:03+00:00</td>\n",
       "      <td>@Trevornoah it's your right to question the 'g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  \\\n",
       "0    2022-04-29 16:30:18+00:00   \n",
       "1    2022-04-29 16:28:17+00:00   \n",
       "2    2022-04-29 15:42:46+00:00   \n",
       "3    2022-04-29 15:32:51+00:00   \n",
       "4    2022-04-29 15:32:21+00:00   \n",
       "...                        ...   \n",
       "9995 2021-12-03 21:04:21+00:00   \n",
       "9996 2021-12-03 20:55:02+00:00   \n",
       "9997 2021-12-03 20:39:51+00:00   \n",
       "9998 2021-12-03 20:38:08+00:00   \n",
       "9999 2021-12-03 20:17:03+00:00   \n",
       "\n",
       "                                                content  \n",
       "0     @TulsiGabbard I never agree with you,but this ...  \n",
       "1     @MauricioContrer Hola vecino! Depende del stoc...  \n",
       "2     Moderna Stock: Everything You Need To Know | v...  \n",
       "3     Moderna Files to Expand Conditional Marketing ...  \n",
       "4     Moderna Files to Expand Conditional Marketing ...  \n",
       "...                                                 ...  \n",
       "9995  @ogaten10 @AkhigbeSam_ Moderna, plitzer and ot...  \n",
       "9996  @miikee_t Been saying to buy moderna stock sin...  \n",
       "9997  Donc vs avez eu vos 2 doses de #Pfizer mais co...  \n",
       "9998  Pfizer and Moderna are projected to make $93 B...  \n",
       "9999  @Trevornoah it's your right to question the 'g...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moderna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnr1 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Moderna\" since:2020-01-01,until:2022-01-01 min_faves:500').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnr2 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Moderna stock\" since:2020-01-01,until:2022-01-01').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnr3 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"MRNA stock\" since:2020-01-01,until:2022-01-01').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnr4 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    'from:moderna_tx since:2020-01-01,until:2022-01-01 ').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnr = pd.concat([mdnr1, mdnr2,mdnr3,mdnr4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnr.to_csv('Moderna_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>renderedContent</th>\n",
       "      <th>id</th>\n",
       "      <th>user</th>\n",
       "      <th>replyCount</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>quoteCount</th>\n",
       "      <th>...</th>\n",
       "      <th>retweetedTweet</th>\n",
       "      <th>quotedTweet</th>\n",
       "      <th>inReplyToTweetId</th>\n",
       "      <th>inReplyToUser</th>\n",
       "      <th>mentionedUsers</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>place</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>cashtags</th>\n",
       "      <th>card</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://twitter.com/JustinTrudeau/status/15200...</td>\n",
       "      <td>2022-04-29 17:13:22+00:00</td>\n",
       "      <td>Vaccines save lives, and it’s important that w...</td>\n",
       "      <td>Vaccines save lives, and it’s important that w...</td>\n",
       "      <td>1520088866111344642</td>\n",
       "      <td>{'username': 'JustinTrudeau', 'id': 14260960, ...</td>\n",
       "      <td>561</td>\n",
       "      <td>158</td>\n",
       "      <td>946</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://twitter.com/CTVNews/status/15200537140...</td>\n",
       "      <td>2022-04-29 14:53:41+00:00</td>\n",
       "      <td>Moderna Montreal factory will make Canada an m...</td>\n",
       "      <td>Moderna Montreal factory will make Canada an m...</td>\n",
       "      <td>1520053714043736070</td>\n",
       "      <td>{'username': 'CTVNews', 'id': 203123011, 'disp...</td>\n",
       "      <td>523</td>\n",
       "      <td>182</td>\n",
       "      <td>827</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'Moderna Montreal factory will make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://twitter.com/FilosofiaMderna/status/152...</td>\n",
       "      <td>2022-04-29 14:36:58+00:00</td>\n",
       "      <td>https://t.co/x3hBVrYFkC</td>\n",
       "      <td>https://t.co/x3hBVrYFkC</td>\n",
       "      <td>1520049506779291648</td>\n",
       "      <td>{'username': 'FilosofiaMderna', 'id': 73808271...</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>1825</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://twitter.com/bernibravo14/status/151995...</td>\n",
       "      <td>2022-04-29 08:08:12+00:00</td>\n",
       "      <td>confirmado una hepatitis inmunomediada secunda...</td>\n",
       "      <td>confirmado una hepatitis inmunomediada secunda...</td>\n",
       "      <td>1519951672608444418</td>\n",
       "      <td>{'username': 'bernibravo14', 'id': 14403968410...</td>\n",
       "      <td>16</td>\n",
       "      <td>859</td>\n",
       "      <td>883</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://twitter.com/LeichsenringC/status/15199...</td>\n",
       "      <td>2022-04-29 07:25:52+00:00</td>\n",
       "      <td>1- Finalmente um estudo que possibilita associ...</td>\n",
       "      <td>1- Finalmente um estudo que possibilita associ...</td>\n",
       "      <td>1519941018732408832</td>\n",
       "      <td>{'username': 'LeichsenringC', 'id': 1063504207...</td>\n",
       "      <td>19</td>\n",
       "      <td>254</td>\n",
       "      <td>504</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'title': 'Severe de novo liver injury after M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21788</th>\n",
       "      <td>https://twitter.com/moderna_tx/status/12141744...</td>\n",
       "      <td>2020-01-06 13:18:36+00:00</td>\n",
       "      <td>Addressing major causes of respiratory infecti...</td>\n",
       "      <td>Addressing major causes of respiratory infecti...</td>\n",
       "      <td>1214174429229592577</td>\n",
       "      <td>{'username': 'moderna_tx', 'id': 2227355222, '...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[RSV, hMPV, InfectiousDisease, mRNA]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21789</th>\n",
       "      <td>https://twitter.com/moderna_tx/status/12141672...</td>\n",
       "      <td>2020-01-06 12:50:03+00:00</td>\n",
       "      <td>At R&amp;amp;D Day, we were excited to announce po...</td>\n",
       "      <td>At R&amp;amp;D Day, we were excited to announce po...</td>\n",
       "      <td>1214167242168061953</td>\n",
       "      <td>{'username': 'moderna_tx', 'id': 2227355222, '...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[cytomegalovirus, CMV, mRNA]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21790</th>\n",
       "      <td>https://twitter.com/moderna_tx/status/12141584...</td>\n",
       "      <td>2020-01-06 12:14:56+00:00</td>\n",
       "      <td>From our beginning, we’ve been working to adva...</td>\n",
       "      <td>From our beginning, we’ve been working to adva...</td>\n",
       "      <td>1214158403444072448</td>\n",
       "      <td>{'username': 'moderna_tx', 'id': 2227355222, '...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[mRNA, CMV, RSV, hMPV, Zika]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21791</th>\n",
       "      <td>https://twitter.com/moderna_tx/status/12141558...</td>\n",
       "      <td>2020-01-06 12:04:48+00:00</td>\n",
       "      <td>https://t.co/uUrCE8i4xy</td>\n",
       "      <td>https://t.co/uUrCE8i4xy</td>\n",
       "      <td>1214155855043661824</td>\n",
       "      <td>{'username': 'moderna_tx', 'id': 2227355222, '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21792</th>\n",
       "      <td>https://twitter.com/moderna_tx/status/12141546...</td>\n",
       "      <td>2020-01-06 12:00:05+00:00</td>\n",
       "      <td>Read about our 2019 progress in this letter to...</td>\n",
       "      <td>Read about our 2019 progress in this letter to...</td>\n",
       "      <td>1214154669951475716</td>\n",
       "      <td>{'username': 'moderna_tx', 'id': 2227355222, '...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[mRNA]</td>\n",
       "      <td>[mRNA]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21793 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  \\\n",
       "0      https://twitter.com/JustinTrudeau/status/15200...   \n",
       "1      https://twitter.com/CTVNews/status/15200537140...   \n",
       "2      https://twitter.com/FilosofiaMderna/status/152...   \n",
       "3      https://twitter.com/bernibravo14/status/151995...   \n",
       "4      https://twitter.com/LeichsenringC/status/15199...   \n",
       "...                                                  ...   \n",
       "21788  https://twitter.com/moderna_tx/status/12141744...   \n",
       "21789  https://twitter.com/moderna_tx/status/12141672...   \n",
       "21790  https://twitter.com/moderna_tx/status/12141584...   \n",
       "21791  https://twitter.com/moderna_tx/status/12141558...   \n",
       "21792  https://twitter.com/moderna_tx/status/12141546...   \n",
       "\n",
       "                           date  \\\n",
       "0     2022-04-29 17:13:22+00:00   \n",
       "1     2022-04-29 14:53:41+00:00   \n",
       "2     2022-04-29 14:36:58+00:00   \n",
       "3     2022-04-29 08:08:12+00:00   \n",
       "4     2022-04-29 07:25:52+00:00   \n",
       "...                         ...   \n",
       "21788 2020-01-06 13:18:36+00:00   \n",
       "21789 2020-01-06 12:50:03+00:00   \n",
       "21790 2020-01-06 12:14:56+00:00   \n",
       "21791 2020-01-06 12:04:48+00:00   \n",
       "21792 2020-01-06 12:00:05+00:00   \n",
       "\n",
       "                                                 content  \\\n",
       "0      Vaccines save lives, and it’s important that w...   \n",
       "1      Moderna Montreal factory will make Canada an m...   \n",
       "2                                https://t.co/x3hBVrYFkC   \n",
       "3      confirmado una hepatitis inmunomediada secunda...   \n",
       "4      1- Finalmente um estudo que possibilita associ...   \n",
       "...                                                  ...   \n",
       "21788  Addressing major causes of respiratory infecti...   \n",
       "21789  At R&amp;D Day, we were excited to announce po...   \n",
       "21790  From our beginning, we’ve been working to adva...   \n",
       "21791                            https://t.co/uUrCE8i4xy   \n",
       "21792  Read about our 2019 progress in this letter to...   \n",
       "\n",
       "                                         renderedContent                   id  \\\n",
       "0      Vaccines save lives, and it’s important that w...  1520088866111344642   \n",
       "1      Moderna Montreal factory will make Canada an m...  1520053714043736070   \n",
       "2                                https://t.co/x3hBVrYFkC  1520049506779291648   \n",
       "3      confirmado una hepatitis inmunomediada secunda...  1519951672608444418   \n",
       "4      1- Finalmente um estudo que possibilita associ...  1519941018732408832   \n",
       "...                                                  ...                  ...   \n",
       "21788  Addressing major causes of respiratory infecti...  1214174429229592577   \n",
       "21789  At R&amp;D Day, we were excited to announce po...  1214167242168061953   \n",
       "21790  From our beginning, we’ve been working to adva...  1214158403444072448   \n",
       "21791                            https://t.co/uUrCE8i4xy  1214155855043661824   \n",
       "21792  Read about our 2019 progress in this letter to...  1214154669951475716   \n",
       "\n",
       "                                                    user  replyCount  \\\n",
       "0      {'username': 'JustinTrudeau', 'id': 14260960, ...         561   \n",
       "1      {'username': 'CTVNews', 'id': 203123011, 'disp...         523   \n",
       "2      {'username': 'FilosofiaMderna', 'id': 73808271...           5   \n",
       "3      {'username': 'bernibravo14', 'id': 14403968410...          16   \n",
       "4      {'username': 'LeichsenringC', 'id': 1063504207...          19   \n",
       "...                                                  ...         ...   \n",
       "21788  {'username': 'moderna_tx', 'id': 2227355222, '...           0   \n",
       "21789  {'username': 'moderna_tx', 'id': 2227355222, '...           0   \n",
       "21790  {'username': 'moderna_tx', 'id': 2227355222, '...           0   \n",
       "21791  {'username': 'moderna_tx', 'id': 2227355222, '...           0   \n",
       "21792  {'username': 'moderna_tx', 'id': 2227355222, '...           0   \n",
       "\n",
       "       retweetCount  likeCount  quoteCount  ...  retweetedTweet quotedTweet  \\\n",
       "0               158        946          58  ...            None        None   \n",
       "1               182        827          87  ...            None        None   \n",
       "2               138       1825           8  ...            None        None   \n",
       "3               859        883          38  ...            None        None   \n",
       "4               254        504          16  ...            None        None   \n",
       "...             ...        ...         ...  ...             ...         ...   \n",
       "21788             1          3           0  ...            None        None   \n",
       "21789             2         10           0  ...            None        None   \n",
       "21790             2          5           0  ...            None        None   \n",
       "21791             0          3           0  ...            None        None   \n",
       "21792             1          5           0  ...            None        None   \n",
       "\n",
       "      inReplyToTweetId inReplyToUser mentionedUsers coordinates place  \\\n",
       "0                  NaN          None           None        None  None   \n",
       "1                  NaN          None           None        None  None   \n",
       "2                  NaN          None           None        None  None   \n",
       "3                  NaN          None           None        None  None   \n",
       "4                  NaN          None           None        None  None   \n",
       "...                ...           ...            ...         ...   ...   \n",
       "21788              NaN          None           None        None  None   \n",
       "21789              NaN          None           None        None  None   \n",
       "21790              NaN          None           None        None  None   \n",
       "21791              NaN          None           None        None  None   \n",
       "21792              NaN          None           None        None  None   \n",
       "\n",
       "                                   hashtags cashtags  \\\n",
       "0                                      None     None   \n",
       "1                                      None     None   \n",
       "2                                      None     None   \n",
       "3                                      None     None   \n",
       "4                                      None     None   \n",
       "...                                     ...      ...   \n",
       "21788  [RSV, hMPV, InfectiousDisease, mRNA]     None   \n",
       "21789          [cytomegalovirus, CMV, mRNA]     None   \n",
       "21790          [mRNA, CMV, RSV, hMPV, Zika]     None   \n",
       "21791                                  None     None   \n",
       "21792                                [mRNA]   [mRNA]   \n",
       "\n",
       "                                                    card  \n",
       "0                                                   None  \n",
       "1      {'title': 'Moderna Montreal factory will make ...  \n",
       "2                                                   None  \n",
       "3                                                   None  \n",
       "4      {'title': 'Severe de novo liver injury after M...  \n",
       "...                                                  ...  \n",
       "21788                                               None  \n",
       "21789                                               None  \n",
       "21790                                               None  \n",
       "21791                                               None  \n",
       "21792                                               None  \n",
       "\n",
       "[21793 rows x 28 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdnr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from investopedia\n",
    "fin_news = ['CNBC','Benzinga','Stocktwits','BreakoutStocks','bespokeinvest',\n",
    "           'WSJMarkets','Stephanie_Link','nytimesbusiness','IBDinvestors','WSJDealJournal',\n",
    "           'MarketWatch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnr = []\n",
    "for acc in fin_news:\n",
    "    \n",
    "    df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Moderna\" from:{} since:2020-01-01,until:2022-01-01'.format(acc)).get_items(),10000))\n",
    "    mdnr.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acc in fin_news:\n",
    "    \n",
    "    df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"MRNA\" from:{} since:2020-01-01,until:2022-01-01'.format(acc)).get_items(),10000))\n",
    "    mdnr.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnr_news = pd.concat(mdnr,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdnr_news.to_csv('Moderna_news.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Johnson and Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj1 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Johnson & Johnson\" since:2020-01-01,until:2022-01-01 min_faves:500').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj2 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Johnson and Johnson\" since:2020-01-01,until:2022-01-01 min_faves:500').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj3 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"JNJ\" since:2020-01-01,until:2022-01-01').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj4 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    'from:JNJNews since:2020-01-01,until:2022-01-01 ').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "jj5= pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"JNJ stock\" since:2020-01-01,until:2022-01-01').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj = pd.concat([jj1,jj2,jj3,jj4,jj5],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj.to_csv('JNJ_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj = []\n",
    "for acc in fin_news:\n",
    "    \n",
    "    df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Johnson & Johnson\" from:{} since:2020-01-01,until:2022-01-01'.format(acc)).get_items(),10000))\n",
    "    jnj.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acc in fin_news:\n",
    "    \n",
    "    df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Johnson and Johnson\" from:{} since:2020-01-01,until:2022-01-01'.format(acc)).get_items(),10000))\n",
    "    jnj.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "for acc in fin_news:\n",
    "    \n",
    "    df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"JNJ\" from:{} since:2020-01-01,until:2022-01-01'.format(acc)).get_items(),10000))\n",
    "    jnj.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj_news = pd.concat(jnj,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj_news.to_csv('JNJ_news.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pfizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf1 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Pfizer\" since:2020-01-01,until:2022-01-01 min_faves:500 lang:en').get_items(),20000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf2 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"PFE stock\" since:2020-01-01,until:2022-01-01 lang:en').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf3 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Pfizer Stock\" since:2020-01-01,until:2022-01-01 lang:en').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf4 = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    'from:pfizer since:2020-01-01,until:2022-01-01').get_items(),10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfe = pd.concat([pf1,pf2,pf3,pf4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfe.to_csv('PFE_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfe_lst = []\n",
    "for acc in fin_news:\n",
    "    \n",
    "    df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"Pfizer\" from:{} since:2020-01-01,until:2022-01-01 lang:en'.format(acc)).get_items(),10000))\n",
    "    pfe_lst.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfe_news = pd.concat(pfe_lst,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfe_news.to_csv('PFE_news_tweets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (4.16.2)\n",
      "Requirement already satisfied: sacremoses in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: filelock in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (0.11.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2020.10.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (4.50.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: requests in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from transformers) (2.24.0)\n",
      "Requirement already satisfied: six in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: click in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/Bennyw/opt/anaconda3/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from transformers import InputExample, InputFeatures\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ffeb7994684049b76d304857742a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=570.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6869dd8eaf734c0cbff47d3ea824b1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=536063208.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4dcc63ca1643e5af6a49a278f8b016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31601c78e16448cab6107d0125d4153b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=231508.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae9d64b014b34bb7bee1d4611005f9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=466062.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the true value of sentiment from price change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj_stock = pd.read_csv(\"/Users/Bennyw/Desktop/DS301 project/acc2022treelinearcascades_stocks-master/data/jnj.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj_stock['change']= jnj_stock[[' Close']].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj_stock.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "conditions = [\n",
    "    (jnj_stock['change'] == 0),\n",
    "    (jnj_stock['change'] > 0),\n",
    "    (jnj_stock['change'] < 0)\n",
    "]\n",
    "\n",
    "values = ['0', '1', '-1']\n",
    "\n",
    "jnj_stock['Senti'] = np.select(conditions, values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj_stock['Dt']=pd.to_datetime(jnj_stock['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "jnj_stock.to_csv('jnj_price_senti.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "path = \"/Users/Bennyw/Desktop/DS301 project/stock_tweets\"\n",
    "#file_lst = os.listdir(\"/Users/Bennyw/Desktop/DS301 project/stock_tweets\")\n",
    "csvs = glob.glob(os.path.join(path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/Bennyw/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Bennyw/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Bennyw/Desktop/DS301 project/stock_tweets/JNJ_news_tweets.csv\n",
      "/Users/Bennyw/Desktop/DS301 project/stock_tweets/Moderna_news_tweets.csv\n",
      "/Users/Bennyw/Desktop/DS301 project/stock_tweets/Moderna_tweets.csv\n",
      "/Users/Bennyw/Desktop/DS301 project/stock_tweets/PFE_news_tweets.csv\n",
      "/Users/Bennyw/Desktop/DS301 project/stock_tweets/JNJ_tweets.csv\n",
      "/Users/Bennyw/Desktop/DS301 project/stock_tweets/PFE_tweets.csv\n",
      "Processing: /Users/Bennyw/Desktop/DS301 project/stock_tweets/JNJ_news_tweets.csv\n",
      "Processing: /Users/Bennyw/Desktop/DS301 project/stock_tweets/Moderna_news_tweets.csv\n",
      "Processing: /Users/Bennyw/Desktop/DS301 project/stock_tweets/Moderna_tweets.csv\n",
      "Processing: /Users/Bennyw/Desktop/DS301 project/stock_tweets/PFE_news_tweets.csv\n",
      "Processing: /Users/Bennyw/Desktop/DS301 project/stock_tweets/JNJ_tweets.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'likeCount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'likeCount'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-415-988a8eae30f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0mdf_notgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentiment_not_grouped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_lst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mdf_grouped_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_sentiment_grouped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_notgrouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;31m#%%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-415-988a8eae30f2>\u001b[0m in \u001b[0;36mget_sentiment_grouped\u001b[0;34m(df_notgrouped)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_notgrouped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mdf_groupedlikes\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"likeCount\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mdf_groupedlikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_groupedlikes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'likeCount'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr 29 14:18:38 2022\n",
    "\n",
    "@author: DingJin, Yichen Guo\n",
    "\"\"\"\n",
    "\n",
    "#%%\n",
    "'''\n",
    "import packages\n",
    "'''\n",
    "\n",
    "from afinn import Afinn\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from stop_words import get_stop_words\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "import dask.dataframe as dd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "sw_1 = list(STOP_WORDS)\n",
    "sw_2 = list(get_stop_words('en'))\n",
    "sw_3 = [\"moderna\",\"mrna\",\"pfizer\",'pfe','jnj','j&j','jj','\\n']\n",
    "stopwords = list(set(sw_1)|set(sw_2)|set(sw_3))\n",
    "\n",
    "nltk.download(\"words\")\n",
    "nltk.download('stopwords')\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "afinn = Afinn()\n",
    "\n",
    "#%%\n",
    "'''\n",
    "file_lst = [\"Moderna_tweets.csv\", \"Moderna_news_tweets.csv\",\\\n",
    "            \"JNJ_news_tweets.csv\", \"JNJ_tweets.csv\",\\\n",
    "            \"PFE_news_tweets.csv\", \"PFE_tweets.csv\"]\n",
    "'''\n",
    "file_lst = csvs\n",
    "\n",
    "#stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "#%%\n",
    "from nltk.tokenize import word_tokenize\n",
    "def lemmatize_words(words):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemma = []\n",
    "    for word in word_tokenize(words):\n",
    "        lemma.append(wordnet_lemmatizer.lemmatize(word))\n",
    "    sent = \" \".join(lemma)\n",
    "    \n",
    "    return sent\n",
    "\n",
    "def remove_non_english(sent):\n",
    "\n",
    "    words = set(nltk.corpus.words.words())\n",
    "\n",
    "    sent = \" \".join(w for w in nltk.wordpunct_tokenize(sent) \\\n",
    "             if w.lower() in words or not w.isalpha())\n",
    "    \n",
    "    return sent\n",
    "\n",
    "def remove_puc_stop_url(sent):\n",
    "    \n",
    "    try:\n",
    "        start = re.search(\"http\", sent).span()[0]\n",
    "        sent = sent[:start]\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    punc = string.punctuation\n",
    "    sent = [x for x in sent if x not in punc]\n",
    "    sent = \"\".join(sent)\n",
    "\n",
    "    tokens = sent.split(\" \")\n",
    "    tokens = [x for x in tokens if x not in stopwords]\n",
    "    sent = \" \".join(tokens)\n",
    "\n",
    "    return sent\n",
    "\n",
    "def get_sentiment(sent):\n",
    "    \n",
    "    return afinn.score(sent)\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "def get_sentiment_not_grouped(file_lst):\n",
    "    \n",
    "    return_dict = dict()\n",
    "    \n",
    "    for file_name in file_lst:\n",
    "        \n",
    "        print(file_name)\n",
    "        \n",
    "        df = pd.read_csv(file_name,encoding = \"ISO-8859-1\")\n",
    "        df = df[[\"date\", \"content\", \"likeCount\"]]\n",
    "        df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "        #df[\"date\"] = df[\"date\"].map(lambda x: x.split(\" \")[0])\n",
    "        #df[\"date\"] = df[\"date\"].map(lambda x: datetime.date(int(x.split(\"-\")[0]), \\\n",
    "          #int(x.split(\"-\")[1]), int(x.split(\"-\")[2])))\n",
    "        df[\"datetime\"] = pd.to_datetime(df['date'],errors='coerce').dt.date\n",
    "        \n",
    "        df[\"content\"] = df[\"content\"].map(lambda x: x.lower())\n",
    "        df['content'].replace(\"[^a-zA-Z]\",\" \",regex=True, inplace=True)\n",
    "        df[\"content\"] = df[\"content\"].map(lambda x: remove_puc_stop_url(x))\n",
    "        df[\"content\"] = df[\"content\"].map(lambda x: remove_non_english(x))\n",
    "        df[\"content\"] = df[\"content\"].map(lambda x: lemmatize_words(x))\n",
    "        df[\"sent_score\"] = df[\"content\"].map(lambda x: get_sentiment(x))\n",
    "        \n",
    "        return_dict[file_name] = df\n",
    "    \n",
    "    return return_dict\n",
    "\n",
    "\n",
    "\n",
    "df_notgrouped = get_sentiment_not_grouped(file_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed\n",
    "def get_sentiment_grouped(df):\n",
    "    \n",
    "    #df['hour']=pd.to_datetime(df['date'],errors='coerce').dt.hour\n",
    "    df = df[pd.to_numeric(df['likeCount'], errors='coerce').notnull()]\n",
    "    df['likeCount'] = df['likeCount'].astype(int)\n",
    "    df['weight']=df['likeCount'] / df.groupby('datetime')['likeCount'].transform('sum')\n",
    "    df['weight'].fillna(0,inplace=True)\n",
    "    df[\"weighted_sent_score\"] = df[\"weight\"]*df[\"sent_score\"]\n",
    "    df_grouped_sent = df.groupby(by = [\"datetime\"]).agg({\"weighted_sent_score\":sum})\n",
    "        \n",
    "    return df_grouped_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the weighted sentiment for each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "JNJ_news_tweets = df_notgrouped['/Users/Bennyw/Desktop/DS301 project/stock_tweets/JNJ_news_tweets.csv']\n",
    "get_sentiment_grouped(JNJ_news_tweets).to_csv('senti_JNJ_news_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "JNJ_tweets = df_notgrouped['/Users/Bennyw/Desktop/DS301 project/stock_tweets/JNJ_tweets.csv']\n",
    "get_sentiment_grouped(JNJ_tweets).to_csv('senti_JNJ_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moderna_news_tweets = df_notgrouped['/Users/Bennyw/Desktop/DS301 project/stock_tweets/Moderna_news_tweets.csv']\n",
    "get_sentiment_grouped(Moderna_news_tweets).to_csv('senti_Moderna_news_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moderna_tweets = df_notgrouped['/Users/Bennyw/Desktop/DS301 project/stock_tweets/Moderna_tweets.csv']\n",
    "get_sentiment_grouped(Moderna_tweets).to_csv('senti_Moderna_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfizer_tweets = df_notgrouped['/Users/Bennyw/Desktop/DS301 project/stock_tweets/PFE_tweets.csv']\n",
    "get_sentiment_grouped(Pfizer_tweets).to_csv('senti_Pfizer_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfizer_news_tweets = df_notgrouped['/Users/Bennyw/Desktop/DS301 project/stock_tweets/PFE_news_tweets.csv']\n",
    "get_sentiment_grouped(Pfizer_news_tweets).to_csv('senti_Pfizer_news_tweets.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
